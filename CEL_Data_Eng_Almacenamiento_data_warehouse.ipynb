{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SELF-msselve/UTN-DataEngineering/blob/main/CEL_Data_Eng_Almacenamiento_data_warehouse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparación de entorno\n",
        "En primer lugar, vamos a instalar librerías y definir funciones para este proceso"
      ],
      "metadata": {
        "id": "EDlvWlWnI77g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sqlalchemy\n",
        "!pip install psycopg2-binary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYwtqgWDI_Z1",
        "outputId": "de0682f3-4df7-4b46-a68c-6cc271a7a2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.28)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (3.0.3)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.9.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from configparser import ConfigParser\n",
        "\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "def connect_to_db(config_file, section, driverdb):\n",
        "    \"\"\"\n",
        "    Crea una conexión a la base de datos especificada en el archivo de configuración.\n",
        "\n",
        "    Parámetros:\n",
        "    config_file (str): La ruta del archivo de configuración.\n",
        "    section (str): La sección del archivo de configuración que contiene los datos de la base de datos.\n",
        "    driverdb (str): El driver de la base de datos a la que se conectará.\n",
        "\n",
        "    Retorna:\n",
        "    Un objeto de conexión a la base de datos.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Lectura del archivo de configuración\n",
        "        parser = ConfigParser()\n",
        "        parser.read(config_file)\n",
        "\n",
        "        # Creación de un diccionario\n",
        "        # donde cargaremos los parámetros de la base de datos\n",
        "        db = {}\n",
        "        if parser.has_section(section):\n",
        "            params = parser.items(section)\n",
        "            db = {param[0]: param[1] for param in params}\n",
        "\n",
        "            # Creación de la conexión a la base de datos\n",
        "            engine = create_engine(\n",
        "                f\"{driverdb}://{db['user']}:{db['pwd']}@{db['host']}:{db['port']}/{db['dbname']}\"\n",
        "            )\n",
        "            return engine\n",
        "\n",
        "        else:\n",
        "            print(\n",
        "                f\"Sección {section} no encontrada en el archivo de configuración.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error al conectarse a la base de datos: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "hDGLRQXDJZVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de continuar, es importante que:\n",
        "1. Crees una instancia de Postgres en Aiven\n",
        "2. y subas o crees en esta sesión de Google un **archivo de configuración** con los datos de conexión y credenciales a Postgres.\n",
        "\n",
        "Te dejo una \"plantilla\", para que crees el archivo e ingreses tus datos de conexión.\n",
        "\n",
        "```\n",
        "[postgres]\n",
        "host=****.aivencloud.com\n",
        "port=15191\n",
        "user=avnadmin\n",
        "pwd=****\n",
        "dbname=defaultdb\n",
        "```"
      ],
      "metadata": {
        "id": "771U3n5vLpiO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVf7Y3WCI2q2"
      },
      "source": [
        "# **Almacenamiento de datos**\n",
        "## Data warehouse\n",
        "\n",
        "En ingeniería de datos, el almacenamiento juega un rol fundamental ya que los resultados de las extracciones y las transformaciones de los datos se deben almacenar en un lugar accesible para su posterior explotación.\n",
        "El sistema donde vamos a almacenar los datos debe ser capaz de soportar grandes volúmenes de información, ser escalable, seguro y eficiente. Los dos principales *sistemas de almacenamiento* que utilizaremos como Data Engineers son el *Data Lake* y el *Data Warehouse*.\n",
        "\n",
        "El data warehouse se caracteriza por contener datos **estructurados**, es decir, datos que **se organizan en tablas** y que se pueden consultar mediante lenguaje SQL. Por ende, uno de los componentes principales de un data warehouse es un motor de base de datos, orientado a la analítica de datos.\n",
        "\n",
        "Dado que el data warehouse contiene datos estructurados, organizados en tablas, debe seguir un modelo de datos que defina la estructura de las tablas y las relaciones entre ellas. El modelo utilizado en la mayoría de los data warehouses es el modelo ***dimensional***.\n",
        "\n",
        "El modelo dimensional se utiliza para facilitar la consulta y el análisis de los datos. En este modelo, los datos se organizan en dos tipos de tablas:\n",
        "- tablas de hechos (fact tables): contienen datos numéricos que se pueden sumarizar (cuantitativos). Por ejemplo, el monto de una venta, la cantidad de productos vendidos, etc.\n",
        "- tablas de dimensiones (dimension tables): contienen datos descriptivos (cualitativos) que se utilizan para filtrar y agrupar los datos de las tablas de hechos. Por ejemplo, datos de clientes, productos, sucursal, fechas, etc.\n",
        "\n",
        "El modelo dimensional se caracteriza además por ser denormalizado, es decir que las tablas de dimensiones contienen redundancia. Esto se hace para evitar la necesidad de hacer demasiados *joins* entre las tablas de hechos y las tablas de dimensiones, lo que agiliza las consultas. La redundancia se sacrifica en pos de la eficiencia en la consulta.\n",
        "\n",
        "Probablemente estés familiarizado con el *modelo relacional* y términos como *normalización* y *formas normales*. En los siguientes enlaces se ilustran las diferencias entre el modelo relacional y el modelo dimensional, en el contexto de un e-commerce.\n",
        "- [Modelo relacional](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*JQLas0Gca3VcP4Y9b-CRvQ.jpeg)\n",
        "- [Modelo dimensional](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*NXuoqqnI6mLsi_sqa8dBow.jpeg)\n",
        "\n",
        "Aparte de tablas de hechos y dimensiones, en un data warehouse contaremos con un área de *staging* donde se almacenarán los datos crudos de forma temporal. Será una capa intermedia, antes de consolidar los datos en el modelo dimensional.\n",
        "[Áreas de un data warehouse](https://media.geeksforgeeks.org/wp-content/uploads/ETL.jpg)\n",
        "\n",
        "En esta notebook, vamos a ver como iniciar la implementación de un data warehouse. Para ello, vamos a utilizar el motor de base de datos *PostgreSQL* y vamos a crear un modelo dimensional para almacenar los datos de un sistema de ventas (clientes y pagos)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDjn-GX6I2q_"
      },
      "source": [
        "Utilizaremos la librería `sqlalchemy` para interactuar con la base de datos desde Python.\n",
        "\n",
        "*Como vamos a interactuar con base de datos Postgres, es necesario tambien el driver de Postgres para Python: `pip install psycopg2-binary` (ya lo instalamos mas arriba)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8sMnpnDI2rD"
      },
      "outputs": [],
      "source": [
        "engine = connect_to_db(\n",
        "    \"pipeline.conf\",\n",
        "    \"postgres\",\n",
        "    \"postgresql+psycopg2\"\n",
        "    )\n",
        "\n",
        "conn = engine.connect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DevtEMA8I2rE"
      },
      "source": [
        "### Tablas de dimensiones\n",
        "#### Slowly Changing Dimensions (SCD)\n",
        "\n",
        "Con respecto a las tablas de dimensiones, es importante tener en cuenta que los datos de las dimensiones pueden cambiar con el tiempo. Por ejemplo, un cliente puede cambiar su dirección, un producto puede cambiar de categoría, etc. Por lo tanto, es necesario tener en cuenta cómo vamos a manejar estos cambios en las tablas de dimensiones.\n",
        "\n",
        "Existen diferentes estrategias para manejar los cambios en las dimensiones y se implementan a través de lo que se conoce como *Slowly Changing Dimensions* (SCD). Existen diferentes tipos de SCD, las mas importantes son:\n",
        "- Tipo 0: No se capturan los cambios. Los datos se mantienen tal como se cargaron inicialmente.\n",
        "- Tipo 1: Se sobrescriben los datos. Los cambios se sobrescriben en la tabla de dimensiones.\n",
        "- Tipo 2: Se agregan nuevas filas. Se mantiene un historial de los cambios. Se suman columnas adicionales para identificar la vigencia de cada fila."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohzNg0gTI2rF"
      },
      "source": [
        "##### Comencemos trabajando con las de tipo 0 y 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqbb7nuWI2rG"
      },
      "source": [
        "Este data warehouse tendrá un área de staging, que contendrá una tabla `payments` y otra `customers`.\n",
        "En el modelo dimensional, tendremos:\n",
        "- Tabla de hechos: `payments_fact`\n",
        "- Tablas de dimensiones: `customer_dim` y `date_dim`\n",
        "\n",
        "Vamos a inicializar la base de datos y a crear las tablas de staging y las tablas de dimensiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXyO8UgiI2rH"
      },
      "outputs": [],
      "source": [
        "create_query = text(\n",
        "        \"\"\"\n",
        "        BEGIN;\n",
        "\n",
        "        CREATE SCHEMA IF NOT EXISTS stage;\n",
        "        CREATE TABLE IF NOT EXISTS stage.customers(\n",
        "            customer_id INT PRIMARY KEY,\n",
        "            customer_fullname VARCHAR(50),\n",
        "            customer_email VARCHAR(50),\n",
        "            customer_phone VARCHAR(50),\n",
        "            customer_address VARCHAR(50)\n",
        "        );\n",
        "        CREATE TABLE IF NOT EXISTS stage.payments(\n",
        "            payment_id INT PRIMARY KEY,\n",
        "            customer_id INT,\n",
        "            amount FLOAT,\n",
        "            payment_date DATE\n",
        "        );\n",
        "\n",
        "        CREATE SCHEMA IF NOT EXISTS datawarehouse;\n",
        "        CREATE TABLE IF NOT EXISTS datawarehouse.customer_dim(\n",
        "            customer_id INT PRIMARY KEY,\n",
        "            customer_fullname VARCHAR(50),\n",
        "            customer_email VARCHAR(50),\n",
        "            customer_phone VARCHAR(50),\n",
        "            customer_address VARCHAR(50)\n",
        "        );\n",
        "        CREATE TABLE IF NOT EXISTS datawarehouse.date_dim(\n",
        "            date_id INT PRIMARY KEY,\n",
        "            day INT,\n",
        "            month INT,\n",
        "            year INT,\n",
        "            quarter INT,\n",
        "            day_of_week INT,\n",
        "            day_of_month INT\n",
        "        );\n",
        "        CREATE TABLE IF NOT EXISTS datawarehouse.payment_fact(\n",
        "            payment_id INT PRIMARY KEY,\n",
        "            customer_id INT,\n",
        "            amount FLOAT,\n",
        "            payment_date_id INT\n",
        "        );\n",
        "\n",
        "        COMMIT;\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(create_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SdkuMiiI2rI"
      },
      "source": [
        "Vamos a cargar datos sobre la tabla calendario `date_dim`. Tendrá todas las fechas del año 2023. Se puede actualizar anualmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrSzsgV7I2rJ"
      },
      "outputs": [],
      "source": [
        "insert_query = text(\n",
        "        \"\"\"\n",
        "        BEGIN;\n",
        "        INSERT INTO datawarehouse.date_dim\n",
        "        SELECT\n",
        "            TO_CHAR(payment_date, 'yyyymmdd')::INT AS date_id,\n",
        "            EXTRACT(DAY FROM payment_date) AS day,\n",
        "            EXTRACT(MONTH FROM payment_date) AS month,\n",
        "            EXTRACT(YEAR FROM payment_date) AS year,\n",
        "            EXTRACT(QUARTER FROM payment_date) AS quarter,\n",
        "            EXTRACT(DOW FROM payment_date) AS day_of_week,\n",
        "            EXTRACT(DAY FROM payment_date) AS day_of_month\n",
        "        FROM generate_series('2023-01-01'::date, '2023-12-31'::date, '1 day'::interval) AS payment_date;\n",
        "        COMMIT;\n",
        "        \"\"\"\n",
        "        )\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(insert_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4nE-LhlI2rJ"
      },
      "source": [
        "Vamos a cargar datos sobre la tabla `customer_dim`, a partir de la tabla `customers` de staging. La estrategia de SCD que vamos a utilizar es la de tipo 0, es decir que no vamos a capturar los cambios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7g1MR4-I2rK"
      },
      "outputs": [],
      "source": [
        "# Carga de una dimension SCD tipo 0\n",
        "insert_query = text(\n",
        "        \"\"\"\n",
        "        BEGIN;\n",
        "\n",
        "        TRUNCATE TABLE stage.customers;\n",
        "        INSERT INTO stage.customers VALUES\n",
        "          (1, 'Emilio Ravenna', 'ravenna@simulacro.com', '111111', 'Libertador 1234'),\n",
        "          (2, 'Mario Santos', 'santos@simulacro.com', '222222', 'Corrientes 5432'),\n",
        "          (3, 'Gabriel Medina', 'medina@simulacro.com', '999999', 'Santa Fe 9876'),\n",
        "          (4, 'Molero', 'molero@simulacro.com', '99999', 'Bv de los sueños rotos 999');\n",
        "\n",
        "        INSERT INTO datawarehouse.customer_dim\n",
        "        SELECT\n",
        "            stg.customer_id,\n",
        "            stg.customer_fullname,\n",
        "            stg.customer_email,\n",
        "            stg.customer_phone,\n",
        "            stg.customer_address\n",
        "        FROM stage.customers AS stg\n",
        "        -- Obtener los registros que no existen en la tabla de dimension\n",
        "        LEFT JOIN datawarehouse.customer_dim AS dim\n",
        "        ON stg.customer_id = dim.customer_id\n",
        "        WHERE dim.customer_id IS NULL;\n",
        "        COMMIT;\n",
        "        \"\"\"\n",
        "        )\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(insert_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpRGFDl2I2rK"
      },
      "source": [
        "Vamos a repetir la carga de datos en la tabla `customer_dim` pero utilizando la estrategia de SCD de tipo 1, es decir que vamos a sobrescribir los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUUd0EjbI2rL"
      },
      "outputs": [],
      "source": [
        "# SCD tipo 1\n",
        "insert_query = text(\n",
        "    \"\"\"\n",
        "    BEGIN;\n",
        "\n",
        "    TRUNCATE TABLE stage.customers;\n",
        "    INSERT INTO stage.customers VALUES\n",
        "          (1, 'Emilio Ravenna', 'ravenna@simulacro.com', '111111', 'Libertador 1234'),\n",
        "          (2, 'Mario Santos', 'santos@simulacro.com', '222222', 'Corrientes 5432'),\n",
        "          (3, 'Gabriel Medina', 'medina@simulacro.com', '99999999', 'Santa Fe 9876'),\n",
        "          (4, 'Molero', 'molero@simulacro.com', 99999, 'Bv de los sueños rotos 345'),\n",
        "          (5, 'Milazzo', 'milazzo@simulacro.com', 3833838, 'Calle Valentia y Fuerza 17')\n",
        "          ;\n",
        "\n",
        "    MERGE INTO datawarehouse.customer_dim AS dim\n",
        "    USING stage.customers AS stg\n",
        "    ON dim.customer_id = stg.customer_id\n",
        "    WHEN MATCHED THEN\n",
        "        UPDATE SET\n",
        "            customer_email = stg.customer_email,\n",
        "            customer_phone = stg.customer_phone,\n",
        "            customer_address = stg.customer_address\n",
        "    WHEN NOT MATCHED THEN\n",
        "        INSERT (customer_id, customer_fullname, customer_email, customer_phone, customer_address)\n",
        "        VALUES (stg.customer_id, stg.customer_fullname, stg.customer_email, stg.customer_phone, stg.customer_address);\n",
        "    COMMIT;\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(insert_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyMRtqJoI2rL"
      },
      "source": [
        "Por último, vamos a cargar datos sobre la tabla `payments_fact` a partir de la tabla `payments` de staging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlOsp8d0I2rL"
      },
      "outputs": [],
      "source": [
        "insert_query = text(\n",
        "    \"\"\"\n",
        "        BEGIN;\n",
        "\n",
        "        TRUNCATE TABLE stage.payments;\n",
        "        INSERT INTO stage.payments VALUES\n",
        "            (1, 1, 100, '2023-01-01'),\n",
        "            (2, 2, 200, '2023-01-02'),\n",
        "            (3, 3, 300, '2023-01-03'),\n",
        "            (4, 4, 400, '2023-01-04'),\n",
        "            (5, 5, 500, '2023-01-05'),\n",
        "            (6, 5, 7000, '2023-01-05'),\n",
        "            (7, 5, 70000, '2023-01-06'),\n",
        "            (8, 5, 70000, '2023-01-06')\n",
        "            ;\n",
        "\n",
        "        INSERT INTO datawarehouse.payment_fact\n",
        "        SELECT\n",
        "            stg.payment_id,\n",
        "            stg.customer_id,\n",
        "            stg.amount,\n",
        "            TO_CHAR(payment_date, 'yyyymmdd')::INT AS payment_date_id\n",
        "        FROM stage.payments AS stg\n",
        "        -- Obtener los registros que no existen en la tabla de hechos\n",
        "        LEFT JOIN datawarehouse.payment_fact AS fact\n",
        "        ON stg.payment_id = fact.payment_id\n",
        "        WHERE fact.payment_id IS NULL;\n",
        "        COMMIT;\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(insert_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEJ4aoEdI2rM"
      },
      "source": [
        "#### Implementación de SCD Tipo 2\n",
        "Para poder implementar la SCD de tipo 2, es necesario re-estructurar el esquema de la base de datos. Por ello, vamos a crear nuevas tablas de hechos y dimensiones. Concretamente, vamos a crear nuevas versiones para `payment_fact` y `customer_dim`. El área de staging se mantienen igual, al igual que `date_dim`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rzj6ljboI2rM"
      },
      "outputs": [],
      "source": [
        "create_query = text(\n",
        "    \"\"\"\n",
        "    BEGIN;\n",
        "    CREATE SCHEMA IF NOT EXISTS datawarehouse;\n",
        "    -- Crear dim SCD tipo 2\n",
        "    CREATE TABLE IF NOT EXISTS datawarehouse.customer_dim_v2(\n",
        "        customer_surrogate_key SERIAL PRIMARY KEY,\n",
        "        customer_id INT,\n",
        "        customer_fullname VARCHAR(50),\n",
        "        customer_email VARCHAR(50),\n",
        "        customer_phone VARCHAR(50),\n",
        "        customer_address VARCHAR(50),\n",
        "        start_date DATE,\n",
        "        end_date DATE,\n",
        "        is_current BOOLEAN\n",
        "    );\n",
        "    CREATE TABLE IF NOT EXISTS datawarehouse.payment_fact_v2(\n",
        "        payment_id INT PRIMARY KEY,\n",
        "        customer_surrogate_key INT,\n",
        "        amount FLOAT,\n",
        "        payment_date_id INT\n",
        "    );\n",
        "    COMMIT\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(create_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Sl3QhiI2rM"
      },
      "source": [
        "Vamos a cargar datos sobre la tabla `customer_dim_v2`, a partir de la tabla `customers` de staging. La estrategia de SCD que vamos a utilizar es la de tipo 2, es decir que vamos a agregar nuevas filas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m4eu2AaI2rN"
      },
      "outputs": [],
      "source": [
        "insert_query = text(\n",
        "    \"\"\"\n",
        "    BEGIN;\n",
        "\n",
        "    TRUNCATE TABLE stage.customers;\n",
        "    INSERT INTO stage.customers VALUES\n",
        "          (1, 'Emilio Ravenna', 'tortugamaritima@simulacro.com', '999999', 'Libertador 1234'),\n",
        "          (2, 'Mario Santos', 'santos@simulacro.com', '0000000', 'Corrientes 5432'),\n",
        "          (3, 'Gabriel Medina', 'medina@simulacro.com', '90000000', 'Jugueteria Simon 39'),\n",
        "          (4, 'Molero', 'molero@simulacro.com', 93939339, 'Bv de los sueños rotos 93')\n",
        "        ;\n",
        "\n",
        "    MERGE INTO datawarehouse.customer_dim_v2 AS dim\n",
        "    USING stage.customers AS stg\n",
        "    ON dim.customer_id = stg.customer_id\n",
        "    -- Marcar el ultimo registro del cliente como finalizado\n",
        "    WHEN MATCHED\n",
        "    AND (dim.customer_email <> stg.customer_email\n",
        "    OR dim.customer_phone <> stg.customer_phone\n",
        "    OR dim.customer_address <> stg.customer_address)\n",
        "    AND dim.is_current = TRUE THEN\n",
        "        UPDATE SET\n",
        "            end_date = CURRENT_DATE,\n",
        "            is_current = FALSE\n",
        "    -- Ingresar registro de un nuevo cliente\n",
        "    WHEN NOT MATCHED THEN\n",
        "        INSERT (customer_id, customer_fullname, customer_email, customer_phone, customer_address, start_date, end_date, is_current)\n",
        "        VALUES (stg.customer_id, stg.customer_fullname, stg.customer_email, stg.customer_phone, stg.customer_address, CURRENT_DATE, NULL, TRUE);\n",
        "\n",
        "    -- Ingresar actualización de un cliente ya existente\n",
        "    INSERT INTO datawarehouse.customer_dim_v2(customer_id, customer_fullname, customer_email, customer_phone, customer_address, start_date, end_date, is_current)\n",
        "    SELECT\n",
        "        stg.customer_id,\n",
        "        stg.customer_fullname,\n",
        "        stg.customer_email,\n",
        "        stg.customer_phone,\n",
        "        stg.customer_address,\n",
        "        CURRENT_DATE, -- start_date\n",
        "        NULL, -- end_date\n",
        "        TRUE -- is_current\n",
        "    FROM stage.customers AS stg\n",
        "    LEFT JOIN datawarehouse.customer_dim_v2 AS dim\n",
        "    ON stg.customer_id = dim.customer_id\n",
        "    WHERE dim.is_current = FALSE\n",
        "    AND (stg.customer_email <> dim.customer_email\n",
        "    OR stg.customer_phone <> dim.customer_phone\n",
        "    OR stg.customer_address <> dim.customer_address);\n",
        "    COMMIT;\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(insert_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUIdKfT5I2rN"
      },
      "outputs": [],
      "source": [
        "# Cargar datos sobre la tabla fact\n",
        "insert_query = text(\n",
        "    \"\"\"\n",
        "    BEGIN;\n",
        "\n",
        "    TRUNCATE TABLE stage.payments;\n",
        "    INSERT INTO stage.payments VALUES\n",
        "        (1, 1, 100, '2023-01-01'),\n",
        "        (2, 1, 200, '2023-01-02'),\n",
        "        (3, 1, 300, '2023-01-03'),\n",
        "        (4, 2, 400, '2023-01-04'),\n",
        "        (5, 2, 500, '2023-01-05'),\n",
        "        (6, 3, 600, '2023-01-06'),\n",
        "        (7, 3, 700, '2023-01-07'),\n",
        "        (8, 3, 800, '2023-01-08'),\n",
        "        (9, 1, 1000, '2023-01-09'),\n",
        "        (10, 2, 10000, '2023-01-09')\n",
        "        ;\n",
        "\n",
        "    INSERT INTO datawarehouse.payment_fact_v2\n",
        "    SELECT\n",
        "        stg.payment_id,\n",
        "        dim.customer_surrogate_key, -- En vez de ingresar el customer_id, se ingresa customer_surrogate_key\n",
        "        stg.amount,\n",
        "        TO_CHAR(payment_date, 'yyyymmdd')::INT AS payment_date_id\n",
        "    FROM stage.payments AS stg\n",
        "    -- Obtener pagos nuevos, que no existen en la tabla fact\n",
        "    LEFT JOIN datawarehouse.payment_fact_v2 AS fact\n",
        "    ON fact.payment_id = stg.payment_id\n",
        "    -- Recuperar la clave surrogada customer_surrogate_key actual\n",
        "    JOIN datawarehouse.customer_dim_v2 AS dim\n",
        "    ON stg.customer_id = dim.customer_id\n",
        "    WHERE dim.is_current = TRUE -- Recuperar clave surrogada actual\n",
        "    AND fact.payment_id IS NULL; -- Obtener solo pagos nuevos\n",
        "    COMMIT;\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "with engine.connect() as conn:\n",
        "    conn.execute(insert_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnHiGZk4I2rO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "utn_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}